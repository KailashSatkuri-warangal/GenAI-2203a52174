{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBt6NRS_HRGm",
        "outputId": "d23c96c8-3863-4e39-e0ae-4a1978ff9fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.3568 - loss: 1.2511 - val_accuracy: 0.5000 - val_loss: 1.0997\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7044 - loss: 0.9958 - val_accuracy: 0.8750 - val_loss: 0.9250\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9141 - loss: 0.8943 - val_accuracy: 0.9583 - val_loss: 0.8172\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8854 - loss: 0.8225 - val_accuracy: 1.0000 - val_loss: 0.7604\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9505 - loss: 0.7436 - val_accuracy: 1.0000 - val_loss: 0.7176\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9792 - loss: 0.6855 - val_accuracy: 1.0000 - val_loss: 0.6676\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9401 - loss: 0.6546 - val_accuracy: 1.0000 - val_loss: 0.6162\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9583 - loss: 0.6101 - val_accuracy: 1.0000 - val_loss: 0.5643\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9349 - loss: 0.5553 - val_accuracy: 1.0000 - val_loss: 0.5333\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9505 - loss: 0.4967 - val_accuracy: 1.0000 - val_loss: 0.4996\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9667 - loss: 0.4865\n",
            "Test accuracy: 0.9666666388511658\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist, cifar10, fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# Select dataset (change this part to switch datasets)\n",
        "dataset = 'iris'  # options: 'mnist', 'cifar10', 'fashion_mnist', 'iris', 'reuters'\n",
        "\n",
        "# Load dataset\n",
        "if dataset == 'mnist':\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "elif dataset == 'cifar10':\n",
        "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "elif dataset == 'fashion_mnist':\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "elif dataset == 'iris':\n",
        "    from sklearn.datasets import load_iris\n",
        "    iris = load_iris()\n",
        "    X, y = iris.data, iris.target\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "else:\n",
        "    raise ValueError(\"Unknown dataset\")\n",
        "\n",
        "# Preprocess data\n",
        "if dataset != 'iris':\n",
        "    X_train = X_train.reshape(X_train.shape[0], -1).astype('float32') / 255.0\n",
        "    X_test = X_test.reshape(X_test.shape[0], -1).astype('float32') / 255.0\n",
        "\n",
        "# One-hot encoding\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.transform(y_test)\n",
        "\n",
        "# Define the Neural Network architecture\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')\n",
        "\n",
        "# Save the model\n",
        "#model.save('multiclass_classification_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " def backward(self, X, y, y_hat, learning_rate):\n",
        "    # Backpropagation\n",
        "    delta2 = (y_hat - y) * self.sigmoid_derivative(self.z2)\n",
        "    delta1 = delta2.dot(self.weights2.T) * self.sigmoid_derivative(self.z1)\n",
        "    self.weights2 -= learning_rate * self.a1.T.dot(delta2)\n",
        "    self.weights1 -= learning_rate * X.T.dot(delta1)\n",
        "\n",
        "def sigmoid(self, z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def sigmoid_derivative(self, z):\n",
        "    return self.sigmoid(z) * (1 - self.sigmoid(z))"
      ],
      "metadata": {
        "id": "QmDvbnySVG8Y"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def _init_(self, input_size, hidden_size, output_size):\n",
        "        # Initialize weights randomly\n",
        "        self.weights1 = np.random.randn(input_size, hidden_size)\n",
        "        self.weights2 = np.random.randn(hidden_size, output_size)\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward propagation\n",
        "        self.z1 = np.dot(X, self.weights1)\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.weights2)\n",
        "        self.y_hat = self.sigmoid(self.z2)\n",
        "        return self.y_hat\n",
        "\n",
        "    def backward(self, X, y, y_hat, learning_rate):\n",
        "        # Backpropagation\n",
        "        delta2 = (y_hat - y) * self.sigmoid_derivative(self.z2)\n",
        "        delta1 = delta2.dot(self.weights2.T) * self.sigmoid_derivative(self.z1)\n",
        "        self.weights2 -= learning_rate * self.a1.T.dot(delta2)\n",
        "        self.weights1 -= learning_rate * X.T.dot(delta1)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def sigmoid_derivative(self, z):\n",
        "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n"
      ],
      "metadata": {
        "id": "txtjX6XLV8uN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the column names to identify the correct target variable name\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I4hPz1tXkzx",
        "outputId": "35a409c1-5cff-4192-cbc1-f55025a904bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['ImageId', 'Label'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "data = pd.read_csv('mnist.csv')\n",
        "target_column = 'Label'  #change the target variable\n",
        "\n",
        "X = data.drop(target_column, axis=1)\n",
        "y = data[target_column]\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "y_binarized = lb.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binarized, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n",
        "print(\"Training target shape:\", y_train.shape)\n",
        "print(\"Testing target shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU9HSnRlWE2T",
        "outputId": "7f155529-bdb8-4e77-991b-3267ea181010"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (22400, 1)\n",
            "Testing set shape: (5600, 1)\n",
            "Training target shape: (22400, 1)\n",
            "Testing target shape: (5600, 1)\n"
          ]
        }
      ]
    }
  ]
}